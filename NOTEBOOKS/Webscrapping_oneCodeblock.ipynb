{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cad5177d",
   "metadata": {},
   "source": [
    "# finale Webscrapping schleifen für Supabase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c87512",
   "metadata": {},
   "source": [
    "## Codeblock: Web Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f8d884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ CSV erfolgreich erstellt mit 55 Einträgen\n",
      "           date                                              title\n",
      "0  Jun 12, 2025     Bitcoin (BTC) to Crash to $90,000? Price Falls\n",
      "1  Jun 12, 2025  Bitcoin Bull Novogratz Says Strategy Copycats ...\n",
      "2  Jun 12, 2025         BlackRock's Bitcoin ETF Breaks Into Top 20\n",
      "3  Jun 12, 2025  Solana (SOL) Golden Cross Secured? Shiba Inu (...\n",
      "4  Jun 11, 2025   $347,000,000 in Bitcoin (BTC) Moved in Two Hours\n"
     ]
    }
   ],
   "source": [
    "'''import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_news(url):\n",
    "    # Seite laden\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Alle News-Container finden\n",
    "    main_blocks = soup.find_all(\"div\", class_=\"news__item\")\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for block in main_blocks:\n",
    "        # Titel und Zeit in jedem Block suchen\n",
    "        title_tag = block.find(\"div\", class_=\"news__item-title\")\n",
    "        time_tag = block.find(\"div\", class_=\"humble\")\n",
    "\n",
    "        if title_tag and time_tag:\n",
    "            title = title_tag.get_text(strip=True)\n",
    "\n",
    "            timing_raw = time_tag.get_text(strip=True)\n",
    "            # Uhrzeit entfernen, falls mit \" - \" getrennt (z.B. \"2025-06-12 - 14:35\")\n",
    "            date_only = timing_raw.split(' - ')[0]\n",
    "\n",
    "            data.append({\n",
    "                \"date\": date_only,\n",
    "                \"title\": title\n",
    "            })\n",
    "\n",
    "    # DataFrame erstellen\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# URL mit Suchbegriff bitcoin\n",
    "url = \"https://u.today/search/node?keys=bitcoin\"\n",
    "\n",
    "# News-Daten scrapen\n",
    "df = scrape_news(url)\n",
    "\n",
    "# CSV speichern (optional)\n",
    "df.to_csv(\"news_ticker.csv\", index=False)\n",
    "\n",
    "print(\"✔️ CSV erfolgreich erstellt mit\", len(df), \"Einträgen\")\n",
    "print(df.head())  # Zeige die ersten Zeilen des DataFrames'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bb3c430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ CSV erfolgreich erstellt mit 45 Einträgen\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Webseite laden\n",
    "url = \"https://u.today/news\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# News-Container finden\n",
    "main_blocks = soup.find_all(\"div\", class_=\"news__item\")\n",
    "\n",
    "data = []\n",
    "\n",
    "for block in main_blocks:\n",
    "    title_tag = block.find(\"div\", class_=\"news__item-title\")\n",
    "    time_tag = block.find(\"div\", class_=\"humble\")\n",
    "\n",
    "    if title_tag and time_tag:\n",
    "        title = title_tag.get_text(strip=True)\n",
    "        timing_raw = time_tag.get_text(strip=True)\n",
    "\n",
    "        # Nur das Datum extrahieren, falls Format \"Jun 12, 2025 - 09:30\"\n",
    "        date_part = timing_raw.split(\" - \")[0].strip()\n",
    "\n",
    "        try:\n",
    "            # In ISO-Format \"2025-06-12\" konvertieren\n",
    "            date_obj = datetime.strptime(date_part, \"%b %d, %Y\")\n",
    "            formatted_date = date_obj.strftime(\"%Y-%m-%d\")\n",
    "        except ValueError:\n",
    "            # Wenn Parsing fehlschlägt, überspringen\n",
    "            print(f\"⚠️ Ungültiges Datumsformat: {date_part}\")\n",
    "            continue\n",
    "\n",
    "        data.append({\n",
    "            \"date\": formatted_date,\n",
    "            \"title\": title\n",
    "        })\n",
    "\n",
    "# DataFrame erstellen und CSV exportieren\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"news_ticker.csv\", index=False)\n",
    "print(\"✔️ CSV erfolgreich erstellt mit\", len(df), \"Einträgen\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac8e93c",
   "metadata": {},
   "source": [
    "# Senden an SUPABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebbdacab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Datenbank aktualisiert.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import psycopg\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "dbconn = os.getenv(\"DATABASE_URL\")\n",
    "\n",
    "def insert_df_to_db(df):\n",
    "    with psycopg.connect(dbconn) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            for _, row in df.iterrows():\n",
    "                try:\n",
    "                    # Datum im Format YYYY-MM-DD parsen\n",
    "                    date = datetime.strptime(row['date'], \"%Y-%m-%d\").date()\n",
    "                    title = row['title']\n",
    "\n",
    "                    cur.execute(\n",
    "                        '''\n",
    "                        INSERT INTO news_ticker(date, title)\n",
    "                        VALUES (%s, %s)\n",
    "                        ON CONFLICT DO NOTHING;\n",
    "                        ''',\n",
    "                        (date, title)\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Fehler bei Zeile: {row}\\n{e}\")\n",
    "\n",
    "    print(\"✅ Datenbank aktualisiert.\")\n",
    "\n",
    "# df ist dein DataFrame aus dem Scraper\n",
    "insert_df_to_db(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
