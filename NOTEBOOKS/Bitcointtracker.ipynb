{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "707146da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install python-dotenv\n",
    "# nur beim ersten Mal ausführen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4190a554",
   "metadata": {},
   "source": [
    "# Sichtbarer Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f5b03f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "#url = \"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=IBM&apikey=8FSRZYX36C4RES04\" \n",
    "#response = requests.get(url)\n",
    "#print(response.status_code)\n",
    "#data = response.json()\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6d668b",
   "metadata": {},
   "source": [
    "#  Key mit .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33f500cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import requests\n",
    "#import os\n",
    "\n",
    "#from dotenv import load_dotenv\n",
    "\n",
    "# # .env-Datei laden\n",
    "# load_dotenv()\n",
    "\n",
    "# # API-Key aus Umgebungsvariable holen\n",
    "# api_key = os.getenv(\"API_ALPHA\")\n",
    "\n",
    "# # URL IBN\n",
    "# url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=IBM&apikey={api_key}\"\n",
    "\n",
    "# # Anfrage senden\n",
    "# response = requests.get(url)\n",
    "# print(response.status_code)\n",
    "\n",
    "# # Antwort verarbeiten\n",
    "# data = response.json()\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43fbb0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f8cdfaf",
   "metadata": {},
   "source": [
    "# Beispiel IBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a2e2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# # .env-Datei laden\n",
    "# load_dotenv()\n",
    "\n",
    "# # API-Key aus Umgebungsvariable holen\n",
    "# api_key = os.getenv(\"API_ALPHA\")\n",
    "\n",
    "# # URL zusammenbauen\n",
    "# url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=IBM&apikey={api_key}\"\n",
    "\n",
    "# # Anfrage senden\n",
    "# response = requests.get(url)\n",
    "# print(\"Status Code:\", response.status_code)\n",
    "\n",
    "# if response.status_code == 200:\n",
    "#     data = response.json()\n",
    "\n",
    "#     # Zeitreihe extrahieren\n",
    "#     time_series = data.get(\"Time Series (Daily)\", {})\n",
    "\n",
    "#     # Sortiert nach Datum (absteigend)\n",
    "#     for date in sorted(time_series.keys(), reverse=True):\n",
    "#         daily_data = time_series[date]\n",
    "#         print(f\"Datum: {date}\")\n",
    "#         print(f\"  Open:   {daily_data['1. open']}\")\n",
    "#         print(f\"  High:   {daily_data['2. high']}\")\n",
    "#         print(f\"  Low:    {daily_data['3. low']}\")\n",
    "#         print(f\"  Close:  {daily_data['4. close']}\")\n",
    "#         print(f\"  Volume: {daily_data['5. volume']}\")\n",
    "#         print(\"-\" * 30)\n",
    "# else:\n",
    "#     print(\"Fehler beim Abrufen der Daten.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f888a6b6",
   "metadata": {},
   "source": [
    "Aufgabe : Entwerfen Sie eine SQL-Tabelle, die die Daten dieses API-Endpunkts enthält. \n",
    "Fordern Sie die Daten anschließend an und bringen Sie sie in die richtige Form. \n",
    "Wenn Sie möchten, können Sie die Daten zunächst in eine SQLite-Datenbank übertragen. \n",
    "Später in dieser Woche werden wir jedoch eine Cloud-Postgres-Datenbank auf Supabase bereitstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac400c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import requests\\nimport os\\nfrom dotenv import load_dotenv\\n\\nload_dotenv()\\napi_key = os.getenv(\"API_ALPHA\")\\n\\nurl = f\"https://www.alphavantage.co/query?function=DIGITAL_CURRENCY_DAILY&symbol=BTC&market=USD&apikey={api_key}\"\\nresponse = requests.get(url)\\ndata = response.json()\\n\\nif \"Time Series (Digital Currency Daily)\" in data:\\n    ts = data[\"Time Series (Digital Currency Daily)\"]\\n    first_date = next(iter(ts))\\n    values = ts[first_date]\\n    print(f\"Datum: {first_date}\")\\n    print(f\"Öffnungskurs: {values.get(\\'1a. open (USD)\\', \\'n.v.\\')}\")\\n    print(f\"Schlusskurs:  {values.get(\\'4a. close (USD)\\', \\'n.v.\\')}\")\\nelse:\\n    print(\"❌ Fehler oder keine Daten erhalten:\")\\n    print(data)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_ALPHA\")\n",
    "\n",
    "url = f\"https://www.alphavantage.co/query?function=DIGITAL_CURRENCY_DAILY&symbol=BTC&market=USD&apikey={api_key}\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "if \"Time Series (Digital Currency Daily)\" in data:\n",
    "    ts = data[\"Time Series (Digital Currency Daily)\"]\n",
    "    first_date = next(iter(ts))\n",
    "    values = ts[first_date]\n",
    "    print(f\"Datum: {first_date}\")\n",
    "    print(f\"Öffnungskurs: {values.get('1a. open (USD)', 'n.v.')}\")\n",
    "    print(f\"Schlusskurs:  {values.get('4a. close (USD)', 'n.v.')}\")\n",
    "else:\n",
    "    print(\"❌ Fehler oder keine Daten erhalten:\")\n",
    "    print(data)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a3a5da",
   "metadata": {},
   "source": [
    "## Bitcointracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80cb4390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b260309f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "          date      open      high       low     close        volume\n",
      "349 2024-06-26  61794.47  62470.00  60656.80  60816.68  11392.798350\n",
      "348 2024-06-27  60818.86  62346.16  60546.94  61615.39  10530.358988\n",
      "347 2024-06-28  61611.43  62170.62  59868.00  60313.35  11381.025874\n",
      "346 2024-06-29  60312.36  61122.66  60273.80  60885.67   3199.036501\n",
      "345 2024-06-30  60884.44  62942.67  60611.01  62668.26   4263.229248\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_ALPHA\")\n",
    "\n",
    "stock = \"BTC\"\n",
    "\n",
    "url = f\"https://www.alphavantage.co/query?function=DIGITAL_CURRENCY_DAILY&symbol={stock}&market=USD&apikey={api_key}\"\n",
    "\n",
    "response = requests.get(url)\n",
    "print(\"Status Code:\", response.status_code)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    time_series = data.get(\"Time Series (Digital Currency Daily)\", {})\n",
    "\n",
    "    if not time_series:\n",
    "        print(\"Keine Zeitreihendaten gefunden. API-Antwort:\")\n",
    "        print(data)\n",
    "    else:\n",
    "        rows = []\n",
    "        for date, daily_data in time_series.items():\n",
    "            rows.append({\n",
    "                \"date\": date,\n",
    "                \"open\": float(daily_data.get(\"1. open\", 0)),\n",
    "                \"high\": float(daily_data.get(\"2. high\", 0)),\n",
    "                \"low\": float(daily_data.get(\"3. low\", 0)),\n",
    "                \"close\": float(daily_data.get(\"4. close\", 0)),\n",
    "                \"volume\": float(daily_data.get(\"5. volume\", 0)),\n",
    "            })\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        df = df.sort_values(by=\"date\")\n",
    "\n",
    "        print(df.head())  # Ausgabe der ersten Zeilen\n",
    "\n",
    "else:\n",
    "    print(\"Fehler beim Abrufen der Daten.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b94a02ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"bitcoin_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d20547",
   "metadata": {},
   "source": [
    "# Script hangt nun die neusten Daten an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29df889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_existing_csv(filepath):\n",
    "    if os.path.exists(filepath):\n",
    "        return pd.read_csv(filepath, parse_dates=[\"date\"])\n",
    "    return pd.DataFrame()\n",
    "\n",
    "def save_data(df, filepath):\n",
    "    df.to_csv(filepath, index=False)\n",
    "\n",
    "def main():\n",
    "    # 1. Daten aus API laden (dein Code hier)\n",
    "\n",
    "    # 2. Bestehende CSV laden\n",
    "    existing_df = load_existing_csv(\"bitcoin_data.csv\")\n",
    "    # 3. Neue Daten in DataFrame df laden (API-Daten)\n",
    "\n",
    "    \n",
    "    # 4. Neue Daten mit bestehendem DataFrame zusammenfügen, doppelte Einträge entfernen\n",
    "    combined_df = pd.concat([existing_df, df]).drop_duplicates(subset=[\"date\"]).sort_values(by=\"date\")\n",
    "    # 5. Speichern\n",
    "    save_data(combined_df, \"bitcoin_data.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ec498b",
   "metadata": {},
   "source": [
    "## Angepasster Code Fügt eine Datei zum bestehdnen CSV an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31858612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354 Datensätze gespeichert in 'bitcoin_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Lade Umgebungsvariablen (API-Key)\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_ALPHA\")\n",
    "\n",
    "# CSV-Dateipfad\n",
    "csv_filepath = \"bitcoin_data.csv\"\n",
    "\n",
    "def fetch_bitcoin_data():\n",
    "    url = f\"https://www.alphavantage.co/query?function=DIGITAL_CURRENCY_DAILY&symbol=BTC&market=USD&apikey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        time_series = data.get(\"Time Series (Digital Currency Daily)\", {})\n",
    "        \n",
    "        records = []\n",
    "        for date, values in time_series.items():\n",
    "            records.append({\n",
    "                \"date\": date,\n",
    "                \"open\": values.get(\"1a. open (USD)\", \"n.v.\"),\n",
    "                \"high\": values.get(\"2a. high (USD)\", \"n.v.\"),\n",
    "                \"low\": values.get(\"3a. low (USD)\", \"n.v.\"),\n",
    "                \"close\": values.get(\"4a. close (USD)\", \"n.v.\"),\n",
    "                \"volume\": values.get(\"5. volume\", \"n.v.\")\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(records)\n",
    "    else:\n",
    "        print(\"Fehler beim Abrufen der API-Daten.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def load_existing_csv(filepath):\n",
    "    if os.path.exists(filepath):\n",
    "        return pd.read_csv(filepath, parse_dates=[\"date\"])\n",
    "    return pd.DataFrame()\n",
    "\n",
    "def save_data(df, filepath):\n",
    "    df.to_csv(filepath, index=False)\n",
    "\n",
    "def main():\n",
    "    # 1. Neue Daten aus der API laden\n",
    " \n",
    "\n",
    "    df = fetch_bitcoin_data()\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    if df.empty:\n",
    "        print(\"Keine neuen Daten verfügbar.\")\n",
    "        return\n",
    "\n",
    "    # 2. Bestehende CSV-Datei laden\n",
    "    existing_df = load_existing_csv(csv_filepath)\n",
    "\n",
    "    # 3. Daten kombinieren, Duplikate entfernen und sortieren\n",
    "    combined_df = pd.concat([existing_df, df])\n",
    "    combined_df = combined_df.drop_duplicates(subset=[\"date\"]).sort_values(by=\"date\")\n",
    "\n",
    "    # 4. CSV speichern\n",
    "    save_data(combined_df, csv_filepath)\n",
    "    print(f\"{len(combined_df)} Datensätze gespeichert in '{csv_filepath}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2baef53",
   "metadata": {},
   "source": [
    "## Verbindung zu SUPABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "356b4cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbconn = os.getenv(\"DBCONN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f237f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b35c0892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.10-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Downloading psycopg2_binary-2.9.10-cp312-cp312-win_amd64.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.2 MB 330.3 kB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.0/1.2 MB 393.8 kB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.1/1.2 MB 655.4 kB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.3/1.2 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.5/1.2 MB 2.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.6/1.2 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 0.7/1.2 MB 2.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 0.9/1.2 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.2/1.2 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 2.6 MB/s eta 0:00:00\n",
      "Installing collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.9.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e22d13",
   "metadata": {},
   "source": [
    "## Servertest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0c4583",
   "metadata": {},
   "source": [
    "Nochmal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8988eb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbindung erfolgreich! Serverzeit: 2025-06-06 14:00:18.575173+00:00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env Datei laden\n",
    "load_dotenv()\n",
    "\n",
    "# Datenbank-URL aus .env holen\n",
    "DATABASE_URL = os.getenv(\"DATABASE_URL\")\n",
    "\n",
    "if not DATABASE_URL:\n",
    "    raise ValueError(\"DATABASE_URL ist nicht gesetzt!\")\n",
    "\n",
    "try:\n",
    "    # Verbindung aufbauen\n",
    "    conn = psycopg2.connect(DATABASE_URL)\n",
    "    \n",
    "    # Cursor erstellen\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # Beispielabfrage\n",
    "    cur.execute(\"SELECT NOW();\")\n",
    "    result = cur.fetchone()\n",
    "    print(\"Verbindung erfolgreich! Serverzeit:\", result[0])\n",
    "    \n",
    "    # Cursor und Verbindung schließen\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Fehler bei der Verbindung:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b92fa1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbindung erfolgreich! Serverzeit: 2025-06-10 09:45:18.043936+00:00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env laden\n",
    "load_dotenv()\n",
    "\n",
    "# DATABASE_URL aus Umgebungsvariablen holen\n",
    "DATABASE_URL = os.getenv(\"DATABASE_URL\")\n",
    "\n",
    "try:\n",
    "    # Verbindung zur DB herstellen\n",
    "    conn = psycopg2.connect(DATABASE_URL)\n",
    "\n",
    "    # Cursor erstellen\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Einfache Abfrage zum Testen\n",
    "    cur.execute(\"SELECT NOW();\")\n",
    "    result = cur.fetchone()\n",
    "    print(\"Verbindung erfolgreich! Serverzeit:\", result[0])\n",
    "\n",
    "    # Cursor und Verbindung schließen\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Fehler bei der Verbindung:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c9f2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6795dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "dbconn = os.getenv(\"DATABASE_URL\")\n",
    "\n",
    "def create_table():\n",
    "    conn = psycopg2.connect(dbconn)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\n",
    "        '''\n",
    "        CREATE TABLE IF NOT EXISTS api_data (\n",
    "            date TIMESTAMP PRIMARY KEY,\n",
    "            open FLOAT,\n",
    "            high FLOAT,\n",
    "            low FLOAT,\n",
    "            close FLOAT,\n",
    "            volume FLOAT\n",
    "        );\n",
    "        '''\n",
    "    )\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "create_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7d8cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad1c395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0300207",
   "metadata": {},
   "source": [
    "Um ältere Daten aus einer anderen CSV-Datei zu ergänzen, kannst du beide CSV-Dateien einlesen, zusammenführen, Duplikate entfernen und dann wie gewohnt weiterverarbeiten.\n",
    "\n",
    "**So geht’s:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b698eac2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'insert_df_to_db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m df_combined\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbitcoin_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Weiterverarbeiten\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[43minsert_df_to_db\u001b[49m(df_combined)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'insert_df_to_db' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Beide Dateien laden\n",
    "df_main = pd.read_csv(\"bitcoin_data.csv\", parse_dates=[\"date\"])\n",
    "df_new = pd.read_csv(\"bitcoin_data_.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "# Kombinieren und nur neue Zeilen übernehmen\n",
    "df_combined = pd.concat([df_main, df_new])\n",
    "\n",
    "# Nur die erste Zeile pro Datum behalten (also df_main bevorzugen)\n",
    "df_combined = df_combined.drop_duplicates(subset=[\"date\"], keep=\"first\")\n",
    "\n",
    "# Nach Datum sortieren (optional, aber sauber)\n",
    "df_combined = df_combined.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# Speichern (optional)\n",
    "df_combined.to_csv(\"bitcoin_data.csv\", index=False)\n",
    "\n",
    "# Weiterverarbeiten\n",
    "insert_df_to_db(df_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339414fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import pandas as pd\n",
    "\n",
    "# Bestehende Daten laden\n",
    "df_main = pd.read_csv(\"bitcoin_data.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "# Ältere Daten laden (z.B. \"bitcoin_old.csv\")\n",
    "df_old = pd.read_csv(\"bitcoin_data_.csv\", parse_dates=[\"date\"])\n",
    "\n",
    "# Zusammenführen und Duplikate entfernen\n",
    "df_combined = pd.merge(df_main, df_old, on=\"date\", how=\"outer\")\n",
    "\n",
    "# Optional: Speichern (überschreibt die Hauptdatei)\n",
    "df_combined.to_csv(\"bitcoin_data_new.csv\", index=False)\n",
    "\n",
    "# Jetzt kannst du df_combined für die Datenbank verwenden:\n",
    "insert_df_to_db(df_combined)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d0b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3860ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>349.0</td>\n",
       "      <td>2024-06-13</td>\n",
       "      <td>68248.59</td>\n",
       "      <td>68474.49</td>\n",
       "      <td>66200.00</td>\n",
       "      <td>66738.85</td>\n",
       "      <td>11916.132111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>348.0</td>\n",
       "      <td>2024-06-14</td>\n",
       "      <td>66746.46</td>\n",
       "      <td>67322.72</td>\n",
       "      <td>65005.00</td>\n",
       "      <td>66004.39</td>\n",
       "      <td>11520.157919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>347.0</td>\n",
       "      <td>2024-06-15</td>\n",
       "      <td>66004.36</td>\n",
       "      <td>66428.57</td>\n",
       "      <td>65800.86</td>\n",
       "      <td>66192.00</td>\n",
       "      <td>2004.142155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>346.0</td>\n",
       "      <td>2024-06-16</td>\n",
       "      <td>66192.00</td>\n",
       "      <td>66931.18</td>\n",
       "      <td>65999.00</td>\n",
       "      <td>66628.75</td>\n",
       "      <td>2118.651634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>345.0</td>\n",
       "      <td>2024-06-17</td>\n",
       "      <td>66629.38</td>\n",
       "      <td>67274.96</td>\n",
       "      <td>65050.00</td>\n",
       "      <td>66481.81</td>\n",
       "      <td>14487.640609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       date      open      high       low     close        volume\n",
       "0       349.0 2024-06-13  68248.59  68474.49  66200.00  66738.85  11916.132111\n",
       "1       348.0 2024-06-14  66746.46  67322.72  65005.00  66004.39  11520.157919\n",
       "2       347.0 2024-06-15  66004.36  66428.57  65800.86  66192.00   2004.142155\n",
       "3       346.0 2024-06-16  66192.00  66931.18  65999.00  66628.75   2118.651634\n",
       "4       345.0 2024-06-17  66629.38  67274.96  65050.00  66481.81  14487.640609"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8253615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-06-06</td>\n",
       "      <td>101570.20</td>\n",
       "      <td>101669.99</td>\n",
       "      <td>101132.91</td>\n",
       "      <td>101655.46</td>\n",
       "      <td>119.048630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-07</td>\n",
       "      <td>104398.00</td>\n",
       "      <td>106000.00</td>\n",
       "      <td>103969.70</td>\n",
       "      <td>105619.02</td>\n",
       "      <td>4141.101243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-08</td>\n",
       "      <td>105619.02</td>\n",
       "      <td>106548.90</td>\n",
       "      <td>105028.30</td>\n",
       "      <td>105784.40</td>\n",
       "      <td>1998.610110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-09</td>\n",
       "      <td>105784.41</td>\n",
       "      <td>110651.12</td>\n",
       "      <td>105368.27</td>\n",
       "      <td>110301.15</td>\n",
       "      <td>6581.176079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-10</td>\n",
       "      <td>110299.69</td>\n",
       "      <td>110349.23</td>\n",
       "      <td>109984.90</td>\n",
       "      <td>110133.46</td>\n",
       "      <td>156.063346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0       date       open       high        low      close  \\\n",
       "358         0.0 2025-06-06  101570.20  101669.99  101132.91  101655.46   \n",
       "359         NaN 2025-06-07  104398.00  106000.00  103969.70  105619.02   \n",
       "360         NaN 2025-06-08  105619.02  106548.90  105028.30  105784.40   \n",
       "361         NaN 2025-06-09  105784.41  110651.12  105368.27  110301.15   \n",
       "362         NaN 2025-06-10  110299.69  110349.23  109984.90  110133.46   \n",
       "\n",
       "          volume  \n",
       "358   119.048630  \n",
       "359  4141.101243  \n",
       "360  1998.610110  \n",
       "361  6581.176079  \n",
       "362   156.063346  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d975c9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Wichtig:**  \n",
    "- Passe `\"bitcoin_old.csv\"` ggf. an deinen Dateinamen an.\n",
    "- Achte darauf, dass die Spaltennamen in beiden CSV-Dateien gleich sind (insbesondere `\"date\"`).\n",
    "\n",
    "Damit hast du alle alten und neuen Daten in einer Datei und kannst sie wie gewohnt in die Datenbank laden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213cfff1",
   "metadata": {},
   "source": [
    "## Finaler Code der df  bei alpha abruft und bei Supabase hochläd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43b8f7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Datenbank aktualisiert.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import psycopg\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env laden\n",
    "load_dotenv()\n",
    "dbconn = os.getenv(\"DATABASE_URL\")\n",
    "\n",
    "# df = ... (dein DataFrame aus Webscraping, wie vorher erstellt)\n",
    "\n",
    "def insert_df_to_db(df_combined):\n",
    "    conn = psycopg.connect(dbconn)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "   \n",
    "        try:\n",
    "            # Datum ggf. anpassen (z. B. 02.06.2025)\n",
    "            date = row['date'].date()\n",
    "            open = row['open']\n",
    "            high = row['high']\n",
    "            low = row['low']\n",
    "            close = row['close']\n",
    "            volume = row['volume']\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "            cur.execute(\n",
    "                '''\n",
    "                INSERT INTO api_data(date, open,high,low,close,volume)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s)\n",
    "                ON CONFLICT DO NOTHING;\n",
    "                ''',\n",
    "                (date, open,high,low,close,volume)\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Fehler bei Zeile: {row}\\n{e}\")\n",
    "\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    print(\"✅ Datenbank aktualisiert.\")\n",
    "\n",
    "insert_df_to_db(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909e912e",
   "metadata": {},
   "source": [
    "   '''\n",
    "        CREATE TABLE IF NOT EXISTS api_data (\n",
    "            date TIMESTAMP PRIMARY KEY,\n",
    "            open FLOAT,\n",
    "            high FLOAT,\n",
    "            low FLOAT,\n",
    "            close FLOAT,\n",
    "            volume FLOAT\n",
    "        );\n",
    "        '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540911e9",
   "metadata": {},
   "source": [
    "    cur.execute(\n",
    "        '''\n",
    "          CREATE TABLE news_ticker (\n",
    "    date DATE,\n",
    "    title TEXT\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
