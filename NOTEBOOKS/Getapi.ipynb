{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "707146da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install python-dotenv\n",
    "# nur beim ersten Mal ausführen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4190a554",
   "metadata": {},
   "source": [
    "# Sichtbarer Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f5b03f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "#url = \"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=IBM&apikey=8FSRZYX36C4RES04\" \n",
    "#response = requests.get(url)\n",
    "#print(response.status_code)\n",
    "#data = response.json()\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6d668b",
   "metadata": {},
   "source": [
    "#  Key mit .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33f500cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{'Information': 'We have detected your API key as LWOPLLLVC2NNF5GX and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env-Datei laden\n",
    "load_dotenv()\n",
    "\n",
    "# API-Key aus Umgebungsvariable holen\n",
    "api_key = os.getenv(\"API_ALPHA\")\n",
    "\n",
    "# URL zusammenbauen\n",
    "url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=IBM&apikey={api_key}\"\n",
    "\n",
    "# Anfrage senden\n",
    "response = requests.get(url)\n",
    "print(response.status_code)\n",
    "\n",
    "# Antwort verarbeiten\n",
    "data = response.json()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43fbb0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "235ffd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{'Information': 'We have detected your API key as LWOPLLLVC2NNF5GX and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env-Datei laden\n",
    "load_dotenv()\n",
    "\n",
    "# API-Key aus Umgebungsvariable holen\n",
    "api_key = os.getenv(\"API_ALPHA\")\n",
    "\n",
    "# URL zusammenbauen\n",
    "url = f\"https://www.alphavantage.co/query?function=SYMBOL_SEARCH&keywords=BC&apikey={api_key}\"\n",
    "\n",
    "# Anfrage senden\n",
    "response = requests.get(url)\n",
    "print(response.status_code)\n",
    "\n",
    "# Antwort verarbeiten\n",
    "data = response.json()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8cdfaf",
   "metadata": {},
   "source": [
    "# Beispiel IBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a2e2e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env-Datei laden\n",
    "load_dotenv()\n",
    "\n",
    "# API-Key aus Umgebungsvariable holen\n",
    "api_key = os.getenv(\"API_ALPHA\")\n",
    "\n",
    "# URL zusammenbauen\n",
    "url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=IBM&apikey={api_key}\"\n",
    "\n",
    "# Anfrage senden\n",
    "response = requests.get(url)\n",
    "print(\"Status Code:\", response.status_code)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "\n",
    "    # Zeitreihe extrahieren\n",
    "    time_series = data.get(\"Time Series (Daily)\", {})\n",
    "\n",
    "    # Sortiert nach Datum (absteigend)\n",
    "    for date in sorted(time_series.keys(), reverse=True):\n",
    "        daily_data = time_series[date]\n",
    "        print(f\"Datum: {date}\")\n",
    "        print(f\"  Open:   {daily_data['1. open']}\")\n",
    "        print(f\"  High:   {daily_data['2. high']}\")\n",
    "        print(f\"  Low:    {daily_data['3. low']}\")\n",
    "        print(f\"  Close:  {daily_data['4. close']}\")\n",
    "        print(f\"  Volume: {daily_data['5. volume']}\")\n",
    "        print(\"-\" * 30)\n",
    "else:\n",
    "    print(\"Fehler beim Abrufen der Daten.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f888a6b6",
   "metadata": {},
   "source": [
    "Aufgabe : Entwerfen Sie eine SQL-Tabelle, die die Daten dieses API-Endpunkts enthält. \n",
    "Fordern Sie die Daten anschließend an und bringen Sie sie in die richtige Form. \n",
    "Wenn Sie möchten, können Sie die Daten zunächst in eine SQLite-Datenbank übertragen. \n",
    "Später in dieser Woche werden wir jedoch eine Cloud-Postgres-Datenbank auf Supabase bereitstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac400c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Fehler oder keine Daten erhalten:\n",
      "{'Information': 'We have detected your API key as LWOPLLLVC2NNF5GX and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_ALPHA\")\n",
    "\n",
    "url = f\"https://www.alphavantage.co/query?function=DIGITAL_CURRENCY_DAILY&symbol=BTC&market=USD&apikey={api_key}\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "if \"Time Series (Digital Currency Daily)\" in data:\n",
    "    ts = data[\"Time Series (Digital Currency Daily)\"]\n",
    "    first_date = next(iter(ts))\n",
    "    values = ts[first_date]\n",
    "    print(f\"Datum: {first_date}\")\n",
    "    print(f\"Öffnungskurs: {values.get('1a. open (USD)', 'n.v.')}\")\n",
    "    print(f\"Schlusskurs:  {values.get('4a. close (USD)', 'n.v.')}\")\n",
    "else:\n",
    "    print(\"❌ Fehler oder keine Daten erhalten:\")\n",
    "    print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b95743ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env-Datei laden\n",
    "load_dotenv()\n",
    "\n",
    "# API-Key aus Umgebungsvariable holen\n",
    "api_key = os.getenv(\"API_ALPHA\")\n",
    "\n",
    "# URL zusammenbauen\n",
    "url = f\"https://www.alphavantage.co/query?function=DIGITAL_CURRENCY_DAILY&symbol=BTC&market=USD&apikey={api_key}\"\n",
    "\n",
    "# Anfrage senden\n",
    "response = requests.get(url)\n",
    "print(\"Status Code:\", response.status_code)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "\n",
    "    # Zeitreihe extrahieren\n",
    "    time_series = data.get(\"Time Series (Daily)\", {})\n",
    "\n",
    "    # Sortiert nach Datum (absteigend)\n",
    "    for date in sorted(time_series.keys(), reverse=True):\n",
    "        daily_data = time_series[date]\n",
    "        print(f\"Datum: {date}\")\n",
    "        print(f\"  Open:   {daily_data['1. open']}\")\n",
    "        print(f\"  High:   {daily_data['2. high']}\")\n",
    "        print(f\"  Low:    {daily_data['3. low']}\")\n",
    "        print(f\"  Close:  {daily_data['4. close']}\")\n",
    "        print(f\"  Volume: {daily_data['5. volume']}\")\n",
    "        print(\"-\" * 30)\n",
    "else:\n",
    "    print(\"Fehler beim Abrufen der Daten.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8c7e11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "Keine Zeitreihendaten gefunden. Antwort:\n",
      "{'Information': 'We have detected your API key as LWOPLLLVC2NNF5GX and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_ALPHA\")\n",
    "\n",
    "url = f\"https://www.alphavantage.co/query?function=DIGITAL_CURRENCY_DAILY&symbol=BTC&market=USD&apikey={api_key}\"\n",
    "\n",
    "response = requests.get(url)\n",
    "print(\"Status Code:\", response.status_code)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json() #Wandelt es in ein Python-Dictionary um und speichert es in data.\n",
    "    time_series = data.get(\"Time Series (Digital Currency Daily)\", {}) #Get BEFEHL\n",
    "\n",
    "    if not time_series:\n",
    "        print(\"Keine Zeitreihendaten gefunden. Antwort:\") # Nur wenn time_series leer ist\n",
    "        print(data)\n",
    "    else:\n",
    "        for date in sorted(time_series.keys(), reverse=True): # Sortiert nach neuste Zuerst\n",
    "            daily_data = time_series[date]\n",
    "            print(f\"Datum: {date}\")\n",
    "            print(f\"  Open:   {daily_data.get('1. open', 'n.v.')}\")\n",
    "            print(f\"  High:   {daily_data.get('2. high', 'n.v.')}\")\n",
    "            print(f\"  Low:    {daily_data.get('3. low', 'n.v.')}\")\n",
    "            print(f\"  Close:  {daily_data.get('4. close', 'n.v.')}\")\n",
    "            print(f\"  Volume: {daily_data.get('5. volume', 'n.v.')}\")\n",
    "            print(\"-\" * 30) # dies druck 30 linien als Trennstrich\n",
    "else:\n",
    "    print(\"Fehler beim Abrufen der Daten.\")\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6cebe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in sorted(time_series.keys(), reverse=True):\n",
    "    daily_data = time_series[date]\n",
    "    print(f\"Datum: {date}\")\n",
    "    print(daily_data)\n",
    "    print(\"-\" * 30)\n",
    "    break  # nur das erste Datum anzeigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45ef85b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# DataFrame erstellen und nach Datum sortieren (aufsteigend)\u001b[39;00m\n\u001b[0;32m     34\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(rows)\n\u001b[1;32m---> 35\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     36\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())  \u001b[38;5;66;03m# die ersten paar Zeilen ausgeben\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cumdi\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\cumdi\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_ALPHA\")\n",
    "\n",
    "stock = \"BTC\"\n",
    "\n",
    "url = f\"https://www.alphavantage.co/query?function=DIGITAL_CURRENCY_DAILY&symbol={stock}&market=USD&apikey={api_key}\"\n",
    "\n",
    "response = requests.get(url)\n",
    "print(\"Status Code:\", response.status_code)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    time_series = data.get(\"Time Series (Digital Currency Daily)\", {})\n",
    "\n",
    "    # Liste für Daten vorbereiten\n",
    "    rows = []\n",
    "\n",
    "    for date, daily_data in time_series.items():\n",
    "        rows.append({\n",
    "            \"date\": date,\n",
    "            \"open\": float(daily_data.get(\"1. open\", 0)),\n",
    "            \"high\": float(daily_data.get(\"2. high\", 0)),\n",
    "            \"low\": float(daily_data.get(\"3. low\", 0)),\n",
    "            \"close\": float(daily_data.get(\"4. close\", 0)),\n",
    "            \"volume\": float(daily_data.get(\"5. volume\", 0)),\n",
    "        })\n",
    "\n",
    "    # DataFrame erstellen und nach Datum sortieren (aufsteigend)\n",
    "    df = pd.DataFrame(rows)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df = df.sort_values(by=\"date\")\n",
    "\n",
    "    print(df.head())  # die ersten paar Zeilen ausgeben\n",
    "\n",
    "else:\n",
    "    print(\"Fehler beim Abrufen der Daten.\")\n",
    "\n",
    "url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b260309f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "Keine Zeitreihendaten gefunden. API-Antwort:\n",
      "{'Information': 'We have detected your API key as 8FSRZYX36C4RES04 and our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_ALPHA\")\n",
    "\n",
    "stock = \"BTC\"\n",
    "\n",
    "url = f\"https://www.alphavantage.co/query?function=DIGITAL_CURRENCY_DAILY&symbol={stock}&market=USD&apikey={api_key}\"\n",
    "\n",
    "response = requests.get(url)\n",
    "print(\"Status Code:\", response.status_code)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    time_series = data.get(\"Time Series (Digital Currency Daily)\", {})\n",
    "\n",
    "    if not time_series:\n",
    "        print(\"Keine Zeitreihendaten gefunden. API-Antwort:\")\n",
    "        print(data)\n",
    "    else:\n",
    "        rows = []\n",
    "        for date, daily_data in time_series.items():\n",
    "            rows.append({\n",
    "                \"date\": date,\n",
    "                \"open\": float(daily_data.get(\"1. open\", 0)),\n",
    "                \"high\": float(daily_data.get(\"2. high\", 0)),\n",
    "                \"low\": float(daily_data.get(\"3. low\", 0)),\n",
    "                \"close\": float(daily_data.get(\"4. close\", 0)),\n",
    "                \"volume\": float(daily_data.get(\"5. volume\", 0)),\n",
    "            })\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        df = df.sort_values(by=\"date\")\n",
    "\n",
    "        print(df.head())  # Ausgabe der ersten Zeilen\n",
    "\n",
    "else:\n",
    "    print(\"Fehler beim Abrufen der Daten.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94a02ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"bitcoin_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d20547",
   "metadata": {},
   "source": [
    "# Script hangt nun die neusten Daten an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29df889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_existing_csv(filepath):\n",
    "    if os.path.exists(filepath):\n",
    "        return pd.read_csv(filepath, parse_dates=[\"date\"])\n",
    "    return pd.DataFrame()\n",
    "\n",
    "def save_data(df, filepath):\n",
    "    df.to_csv(filepath, index=False)\n",
    "\n",
    "def main():\n",
    "    # 1. Daten aus API laden (dein Code hier)\n",
    "\n",
    "    # 2. Bestehende CSV laden\n",
    "    existing_df = load_existing_csv(\"bitcoin_data.csv\")\n",
    "    # 3. Neue Daten in DataFrame df laden (API-Daten)\n",
    "\n",
    "    \n",
    "    # 4. Neue Daten mit bestehendem DataFrame zusammenfügen, doppelte Einträge entfernen\n",
    "    combined_df = pd.concat([existing_df, df]).drop_duplicates(subset=[\"date\"]).sort_values(by=\"date\")\n",
    "    # 5. Speichern\n",
    "    save_data(combined_df, \"bitcoin_data.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ec498b",
   "metadata": {},
   "source": [
    "## Angepasster Code Fügt eine Datei zum bestehdnen CSV an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31858612",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 66\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(combined_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Datensätze gespeichert in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_filepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[32], line 49\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m# 1. Neue Daten aus der API laden\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     df \u001b[38;5;241m=\u001b[39m fetch_bitcoin_data()\n\u001b[1;32m---> 49\u001b[0m     df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeine neuen Daten verfügbar.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\cumdi\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\cumdi\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Lade Umgebungsvariablen (API-Key)\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_ALPHA\")\n",
    "\n",
    "# CSV-Dateipfad\n",
    "csv_filepath = \"bitcoin_data.csv\"\n",
    "\n",
    "def fetch_bitcoin_data():\n",
    "    url = f\"https://www.alphavantage.co/query?function=DIGITAL_CURRENCY_DAILY&symbol=BTC&market=USD&apikey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        time_series = data.get(\"Time Series (Digital Currency Daily)\", {})\n",
    "        \n",
    "        records = []\n",
    "        for date, values in time_series.items():\n",
    "            records.append({\n",
    "                \"date\": date,\n",
    "                \"open\": values.get(\"1a. open (USD)\", \"n.v.\"),\n",
    "                \"high\": values.get(\"2a. high (USD)\", \"n.v.\"),\n",
    "                \"low\": values.get(\"3a. low (USD)\", \"n.v.\"),\n",
    "                \"close\": values.get(\"4a. close (USD)\", \"n.v.\"),\n",
    "                \"volume\": values.get(\"5. volume\", \"n.v.\")\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(records)\n",
    "    else:\n",
    "        print(\"Fehler beim Abrufen der API-Daten.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def load_existing_csv(filepath):\n",
    "    if os.path.exists(filepath):\n",
    "        return pd.read_csv(filepath, parse_dates=[\"date\"])\n",
    "    return pd.DataFrame()\n",
    "\n",
    "def save_data(df, filepath):\n",
    "    df.to_csv(filepath, index=False)\n",
    "\n",
    "def main():\n",
    "    # 1. Neue Daten aus der API laden\n",
    " \n",
    "\n",
    "    df = fetch_bitcoin_data()\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    if df.empty:\n",
    "        print(\"Keine neuen Daten verfügbar.\")\n",
    "        return\n",
    "\n",
    "    # 2. Bestehende CSV-Datei laden\n",
    "    existing_df = load_existing_csv(csv_filepath)\n",
    "\n",
    "    # 3. Daten kombinieren, Duplikate entfernen und sortieren\n",
    "    combined_df = pd.concat([existing_df, df])\n",
    "    combined_df = combined_df.drop_duplicates(subset=[\"date\"]).sort_values(by=\"date\")\n",
    "\n",
    "    # 4. CSV speichern\n",
    "    save_data(combined_df, csv_filepath)\n",
    "    print(f\"{len(combined_df)} Datensätze gespeichert in '{csv_filepath}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2baef53",
   "metadata": {},
   "source": [
    "## Verbindung zu SUPABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356b4cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbconn = os.getenv(\"DBCONN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f237f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e22d13",
   "metadata": {},
   "source": [
    "## Servertest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0c4583",
   "metadata": {},
   "source": [
    "Nochmal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8988eb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbindung erfolgreich! Serverzeit: 2025-05-27 13:21:11.844441+00:00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env Datei laden\n",
    "load_dotenv()\n",
    "\n",
    "# Datenbank-URL aus .env holen\n",
    "DATABASE_URL = os.getenv(\"DATABASE_URL\")\n",
    "\n",
    "if not DATABASE_URL:\n",
    "    raise ValueError(\"DATABASE_URL ist nicht gesetzt!\")\n",
    "\n",
    "try:\n",
    "    # Verbindung aufbauen\n",
    "    conn = psycopg2.connect(DATABASE_URL)\n",
    "    \n",
    "    # Cursor erstellen\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # Beispielabfrage\n",
    "    cur.execute(\"SELECT NOW();\")\n",
    "    result = cur.fetchone()\n",
    "    print(\"Verbindung erfolgreich! Serverzeit:\", result[0])\n",
    "    \n",
    "    # Cursor und Verbindung schließen\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Fehler bei der Verbindung:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92fa1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbindung erfolgreich! Serverzeit: 2025-05-27 13:21:14.649572+00:00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env laden\n",
    "load_dotenv()\n",
    "\n",
    "# DATABASE_URL aus Umgebungsvariablen holen\n",
    "DATABASE_URL = os.getenv(\"DATABASE_URL\")\n",
    "\n",
    "try:\n",
    "    # Verbindung zur DB herstellen\n",
    "    conn = psycopg2.connect(DATABASE_URL)\n",
    "\n",
    "    # Cursor erstellen\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Einfache Abfrage zum Testen\n",
    "    cur.execute(\"SELECT NOW();\")\n",
    "    result = cur.fetchone()\n",
    "    print(\"Verbindung erfolgreich! Serverzeit:\", result[0])\n",
    "\n",
    "    # Cursor und Verbindung schließen\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Fehler bei der Verbindung:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6795dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "dbconn = os.getenv(\"DATABASE_URL\")\n",
    "\n",
    "def create_table():\n",
    "    conn = psycopg2.connect(dbconn)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\n",
    "        '''\n",
    "        CREATE TABLE IF NOT EXISTS api_data (\n",
    "            date TIMESTAMP PRIMARY KEY,\n",
    "            open FLOAT,\n",
    "            high FLOAT,\n",
    "            low FLOAT,\n",
    "            close FLOAT,\n",
    "            volume FLOAT\n",
    "        );\n",
    "        '''\n",
    "    )\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "create_table()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
